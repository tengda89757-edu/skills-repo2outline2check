---
name: ai-empirical-repo-checker
description: |
  AI+实证研究代码仓库标准符合性检查器。系统性评估AI与教育、医学、社科等跨学科实证研究项目的代码仓库，同时检验AI技术标准和实证研究规范，包括方法严谨性、伦理合规、数据治理、可复现性等。
  Use when: 评估AI+跨学科项目质量、论文投稿前检查、IRB/伦理审查准备、基金申请材料审核
---

# AI + Empirical Research Repository Standards Checker

系统性评估AI与跨学科实证研究项目的代码仓库质量。

## 核心定位

该Skill专为**AI+实证研究**设计，涵盖以下研究领域：

| 领域 | 典型研究方向 | 特殊要求 |
|------|-------------|----------|
| AI+教育 | 智能辅导系统、学习分析、自适应学习 | 教育伦理、学习效果评估 |
| AI+医学 | 辅助诊断、影像分析、临床决策支持 | 医学伦理、临床试验规范 |
| AI+社科 | 计算社会科学、社会计算、数字人文 | 社科方法论、隐私保护 |

---

## 三维评估框架

```
┌─────────────────────────────────────────────────────────────┐
│                    三维评估框架                              │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  ┌─────────────────┐                                        │
│  │  AI技术维度      │  算法、模型、代码质量                  │
│  │  (30分)         │                                        │
│  └─────────────────┘                                        │
│           ↘                                                  │
│             ┌─────────────────┐                              │
│             │  实证研究维度    │  方法论、数据、伦理          │
│             │  (40分)         │                              │
│             └─────────────────┘                              │
│           ↗                                                  │
│  ┌─────────────────┐                                        │
│  │  跨学科整合维度  │  理论桥接、实践价值、可推广性          │
│  │  (30分)         │                                        │
│  └─────────────────┘                                        │
│                                                              │
│  总分: 100分                                                 │
│  及格线: 75分                                                │
│  优秀线: 85分                                                │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

---

## 输入要求

### 必需输入
| 输入项 | 格式 | 说明 |
|--------|------|------|
| GitHub仓库URL | string | 或本地路径 |
| README.md | text | 完整内容 |
| 研究领域 | enum | education/medicine/social_science |
| 关键文件列表 | list | 代码、数据、配置文件 |

### 可选输入
- IRB/伦理审批文件
- 预注册方案（如OSF）
- 数据使用协议
- 目标期刊/会议要求

---

## 输出格式

### 结构化审计报告

```markdown
# AI + Empirical Research Repository Standards Report

## 研究信息
- **研究领域**: [AI+教育/AI+医学/AI+社科]
- **研究类型**: [干预研究/观察研究/混合方法/...]
- **人类被试**: [是/否]
- **IRB审批**: [已获批/待审批/不适用]

## 总体评分

**Total Score: XX/100**

| 维度 | 得分 | 满分 | 状态 |
|------|------|------|------|
| AI技术维度 | XX | 30 | ✅/⚠️/❌ |
| 实证研究维度 | XX | 40 | ✅/⚠️/❌ |
| 跨学科整合维度 | XX | 30 | ✅/⚠️/❌ |

**评级**: [优秀(≥85)/合格(≥75)/需改进(<75)]

---

## AI技术维度详细评估

| 检查项 | 得分 | 证据位置 | 状态 |
|--------|------|----------|------|
| 算法/模型描述完整性 | X/5 | [路径] | ✅/❌ |
| 代码质量与可维护性 | X/5 | [路径] | ✅/❌ |
| 实验设计与基线对比 | X/5 | [路径] | ✅/❌ |
| 性能评估与统计报告 | X/5 | [路径] | ✅/❌ |
| 可复现性基础设施 | X/5 | [路径] | ✅/❌ |
| 技术创新与贡献 | X/5 | [路径] | ✅/❌ |

---

## 实证研究维度详细评估

| 检查项 | 得分 | 证据位置 | 状态 |
|--------|------|----------|------|
| 研究设计严谨性 | X/5 | [路径] | ✅/❌ |
| 样本与数据质量 | X/5 | [路径] | ✅/❌ |
| 测量工具信效度 | X/5 | [路径] | ✅/❌ |
| 统计分析方法 | X/5 | [路径] | ✅/❌ |
| 伦理合规性 | X/5 | [路径] | ✅/❌ |
| 数据治理与隐私 | X/5 | [路径] | ✅/❌ |
| 局限性声明 | X/5 | [路径] | ✅/❌ |
| 可推广性讨论 | X/5 | [路径] | ✅/❌ |

---

## 跨学科整合维度详细评估

| 检查项 | 得分 | 证据位置 | 状态 |
|--------|------|----------|------|
| 理论框架整合 | X/5 | [路径] | ✅/❌ |
| 文献综述平衡性 | X/5 | [路径] | ✅/❌ |
| 方法论融合 | X/5 | [路径] | ✅/❌ |
| 实践价值论证 | X/5 | [路径] | ✅/❌ |
| 利益相关者视角 | X/5 | [路径] | ✅/❌ |
| 跨学科贡献声明 | X/5 | [路径] | ✅/❌ |

---

## 领域专属检查

### [AI+教育/AI+医学/AI+社科] 特殊要求

| 检查项 | 状态 | 说明 |
|--------|------|------|
| [领域专属项1] | ✅/❌ | [说明] |
| [领域专属项2] | ✅/❌ | [说明] |

---

## 关键缺失项

| 优先级 | 缺失项 | 影响 | 改进建议 |
|--------|--------|------|----------|
| P0 | [关键缺失] | [影响] | [建议] |
| P1 | [重要缺失] | [影响] | [建议] |

---

## 最终结论

**状态**: [✅ 可进入大纲生成 / ⚠️ 需补充材料 / ❌ 需重大改进]

**核心优势**:
- [优势1]
- [优势2]

**核心改进方向**:
- [方向1]
- [方向2]
```

---

## AI技术维度评估标准

### 1. 算法/模型描述完整性 (5分)

**检查要点**:
- [ ] 是否提供方法的形式化定义？
- [ ] 是否说明算法原理/理论依据？
- [ ] 是否提供伪代码或流程图？
- [ ] 是否说明模型架构和超参数？

**评分标准**:
| 分数 | 标准 |
|------|------|
| 5 | 形式化完整，理论依据充分，可复现 |
| 4 | 描述完整，但部分细节缺失 |
| 3 | 有基本描述，但不够系统 |
| 2 | 描述简略，难以复现 |
| 1 | 描述严重不足 |
| 0 | 缺少方法描述 |

---

### 2. 代码质量与可维护性 (5分)

**检查要点**:
- [ ] 代码结构是否清晰？
- [ ] 是否有充分的注释和文档？
- [ ] 是否遵循编码规范？
- [ ] 是否有单元测试？

**评分标准**:
| 分数 | 标准 |
|------|------|
| 5 | 代码规范，文档完整，有测试覆盖 |
| 4 | 代码清晰，有基本文档 |
| 3 | 代码可读，但文档不足 |
| 2 | 代码结构混乱 |
| 1 | 代码难以理解 |
| 0 | 代码不可用 |

---

### 3. 实验设计与基线对比 (5分)

**检查要点**:
- [ ] 是否有明确的实验设计？
- [ ] 是否与合理的基线对比？
- [ ] 是否进行消融实验？
- [ ] 是否探索边界条件？

**评分标准**:
| 分数 | 标准 |
|------|------|
| 5 | 实验设计严谨，基线全面，消融完整 |
| 4 | 实验设计合理，基线基本完整 |
| 3 | 有实验但设计有缺陷 |
| 2 | 实验不完整 |
| 1 | 实验严重不足 |
| 0 | 缺少实验 |

---

### 4. 性能评估与统计报告 (5分)

**检查要点**:
- [ ] 是否报告多个评估指标？
- [ ] 是否报告统计显著性？
- [ ] 是否报告置信区间/效应量？
- [ ] 是否避免过度拟合声明？

**评分标准**:
| 分数 | 标准 |
|------|------|
| 5 | 指标全面，统计严谨，报告规范 |
| 4 | 指标合理，有统计报告 |
| 3 | 有基本指标，统计不足 |
| 2 | 指标单一或统计缺失 |
| 1 | 评估不充分 |
| 0 | 缺少评估 |

---

### 5. 可复现性基础设施 (5分)

**检查要点**:
- [ ] 是否提供requirements.txt/environment.yml？
- [ ] 是否固定随机种子？
- [ ] 是否提供配置文件？
- [ ] 是否提供Docker/容器化？

**评分标准**:
| 分数 | 标准 |
|------|------|
| 5 | 完全可复现，提供所有必要资源 |
| 4 | 基本可复现，部分资源缺失 |
| 3 | 复现需要额外工作 |
| 2 | 复现困难 |
| 1 | 几乎无法复现 |
| 0 | 无复现支持 |

---

### 6. 技术创新与贡献 (5分)

**检查要点**:
- [ ] 是否明确说明技术创新点？
- [ ] 是否与现有工作区分？
- [ ] 技术贡献是否实质？
- [ ] 是否开源代码/数据？

**评分标准**:
| 分数 | 标准 |
|------|------|
| 5 | 创新明确，贡献实质，已开源 |
| 4 | 有创新点，区分清晰 |
| 3 | 有一定贡献，但创新不足 |
| 2 | 贡献有限 |
| 1 | 缺乏创新 |
| 0 | 无技术贡献 |

---

## 实证研究维度评估标准

### 1. 研究设计严谨性 (5分)

**检查要点**:
- [ ] 研究设计类型是否明确？（RCT/队列/案例研究/混合方法）
- [ ] 是否遵循领域报告指南？（CONSORT/STROBE/SRQR等）
- [ ] 是否有预注册？（临床试验注册/OSF预注册）
- [ ] 研究问题/假设是否明确？

**评分标准**:
| 分数 | 标准 |
|------|------|
| 5 | 设计严谨，有预注册，遵循报告指南 |
| 4 | 设计合理，遵循基本规范 |
| 3 | 设计可行，但规范性不足 |
| 2 | 设计有缺陷 |
| 1 | 设计不严谨 |
| 0 | 设计缺失或不当 |

---

### 2. 样本与数据质量 (5分)

**检查要点**:
- [ ] 样本量是否有依据？（功效分析/饱和度分析）
- [ ] 抽样方法是否说明？
- [ ] 数据收集过程是否透明？
- [ ] 数据质量检查是否进行？

**评分标准**:
| 分数 | 标准 |
|------|------|
| 5 | 样本依据充分，数据质量高，过程透明 |
| 4 | 样本合理，数据质量可接受 |
| 3 | 样本/数据基本可用，但有局限 |
| 2 | 样本不足或数据质量存疑 |
| 1 | 样本/数据问题严重 |
| 0 | 缺少样本说明 |

---

### 3. 测量工具信效度 (5分)

**检查要点**:
- [ ] 测量工具是否验证？（信度/效度报告）
- [ ] 是否使用标准化量表？
- [ ] 自开发工具是否有验证？
- [ ] AI模型评估是否合理？

**评分标准**:
| 分数 | 标准 |
|------|------|
| 5 | 工具验证完整，信效度报告规范 |
| 4 | 使用标准工具，有基本验证 |
| 3 | 工具可用，但验证不足 |
| 2 | 工具选择或验证有问题 |
| 1 | 工具验证严重缺失 |
| 0 | 无测量工具说明 |

---

### 4. 统计分析方法 (5分)

**检查要点**:
- [ ] 统计方法选择是否合理？
- [ ] 是否报告效应量？
- [ ] 是否处理多重比较？
- [ ] 是否报告假设检验前提？

**评分标准**:
| 分数 | 标准 |
|------|------|
| 5 | 方法恰当，报告完整，符合APA/领域标准 |
| 4 | 方法合理，报告基本完整 |
| 3 | 方法可用，但报告不足 |
| 2 | 方法选择有问题 |
| 1 | 统计方法不当 |
| 0 | 缺少统计说明 |

---

### 5. 伦理合规性 (5分)

**检查要点**:
- [ ] 是否获得IRB/伦理委员会审批？
- [ ] 是否说明知情同意过程？
- [ ] 是否保护弱势群体？
- [ ] 是否讨论伦理风险？

**评分标准**:
| 分数 | 标准 |
|------|------|
| 5 | IRB获批，知情同意完整，伦理讨论充分 |
| 4 | 有伦理审批，基本合规 |
| 3 | 有伦理考虑，但不够完整 |
| 2 | 伦理合规存疑 |
| 1 | 伦理问题明显 |
| 0 | 无伦理说明 |

---

### 6. 数据治理与隐私 (5分)

**检查要点**:
- [ ] 是否有数据管理计划？
- [ ] 是否实施数据脱敏/匿名化？
- [ ] 是否符合GDPR/HIPAA等法规？
- [ ] 是否说明数据存储和访问控制？

**评分标准**:
| 分数 | 标准 |
|------|------|
| 5 | 数据治理完善，隐私保护到位，合规 |
| 4 | 有基本数据保护措施 |
| 3 | 有隐私考虑，但措施不足 |
| 2 | 隐私保护薄弱 |
| 1 | 存在隐私风险 |
| 0 | 无隐私保护说明 |

---

### 7. 局限性声明 (5分)

**检查要点**:
- [ ] 是否承认研究局限？
- [ ] 是否讨论选择偏差/混杂因素？
- [ ] 是否说明推广限制？
- [ ] 是否提出改进方向？

**评分标准**:
| 分数 | 标准 |
|------|------|
| 5 | 局限性讨论全面、诚实 |
| 4 | 有基本局限性讨论 |
| 3 | 局限性讨论不够深入 |
| 2 | 局限性讨论过于简略 |
| 1 | 回避关键局限 |
| 0 | 无局限性讨论 |

---

### 8. 可推广性讨论 (5分)

**检查要点**:
- [ ] 是否讨论外部效度？
- [ ] 是否说明适用人群/场景？
- [ ] 是否讨论文化/情境因素？
- [ ] 是否提出未来验证建议？

**评分标准**:
| 分数 | 标准 |
|------|------|
| 5 | 推广性讨论全面，建议具体 |
| 4 | 有基本推广性讨论 |
| 3 | 推广性讨论不够充分 |
| 2 | 推广性讨论简略 |
| 1 | 过度推广或忽视推广限制 |
| 0 | 无推广性讨论 |

---

## 跨学科整合维度评估标准

### 1. 理论框架整合 (5分)

**检查要点**:
- [ ] 是否整合AI和应用领域的理论？
- [ ] 理论框架是否清晰阐述？
- [ ] AI方法与领域理论是否有机结合？
- [ ] 是否提出新的理论洞见？

**评分标准**:
| 分数 | 标准 |
|------|------|
| 5 | 理论整合创新，框架清晰，洞见深刻 |
| 4 | 理论整合合理，框架清晰 |
| 3 | 有理论框架，但整合不够深入 |
| 2 | 理论框架薄弱 |
| 1 | 理论整合表面化 |
| 0 | 缺少理论框架 |

---

### 2. 文献综述平衡性 (5分)

**检查要点**:
- [ ] 是否覆盖AI和应用领域文献？
- [ ] 两领域文献比例是否合理？
- [ ] 是否识别跨学科研究空白？
- [ ] 是否建立领域间对话？

**评分标准**:
| 分数 | 标准 |
|------|------|
| 5 | 文献覆盖全面平衡，空白识别准确 |
| 4 | 文献覆盖较好，基本平衡 |
| 3 | 文献覆盖有偏重 |
| 2 | 文献覆盖不完整 |
| 1 | 文献综述严重偏颇 |
| 0 | 缺少文献综述 |

---

### 3. 方法论融合 (5分)

**检查要点**:
- [ ] AI方法与实证方法是否有效结合？
- [ ] 方法选择是否有跨学科依据？
- [ ] 是否处理方法论冲突？
- [ ] 是否创新方法论？

**评分标准**:
| 分数 | 标准 |
|------|------|
| 5 | 方法融合创新，处理得当 |
| 4 | 方法融合合理有效 |
| 3 | 方法融合基本可行 |
| 2 | 方法融合有问题 |
| 1 | 方法融合表面化 |
| 0 | 方法脱节 |

---

### 4. 实践价值论证 (5分)

**检查要点**:
- [ ] 是否论证实际应用价值？
- [ ] 是否考虑实施可行性？
- [ ] 是否讨论成本效益？
- [ ] 是否有利益相关者参与？

**评分标准**:
| 分数 | 标准 |
|------|------|
| 5 | 实践价值论证充分，可行性分析完整 |
| 4 | 实践价值论证合理 |
| 3 | 有实践价值讨论，但不够深入 |
| 2 | 实践价值论证薄弱 |
| 1 | 实践价值论证缺失 |
| 0 | 无实践价值讨论 |

---

### 5. 利益相关者视角 (5分)

**检查要点**:
- [ ] 是否考虑多方利益相关者？
- [ ] 是否讨论对不同群体的影响？
- [ ] 是否有用户/参与者反馈？
- [ ] 是否考虑公平性和可及性？

**评分标准**:
| 分数 | 标准 |
|------|------|
| 5 | 多方视角全面，影响分析深入 |
| 4 | 利益相关者考虑较全面 |
| 3 | 有基本考虑，但不够全面 |
| 2 | 利益相关者视角不足 |
| 1 | 忽视重要利益相关者 |
| 0 | 无利益相关者讨论 |

---

### 6. 跨学科贡献声明 (5分)

**检查要点**:
- [ ] 是否明确对AI领域的贡献？
- [ ] 是否明确对应用领域的贡献？
- [ ] 是否提出跨学科启示？
- [ ] 贡献声明是否适度？

**评分标准**:
| 分数 | 标准 |
|------|------|
| 5 | 双领域贡献明确，跨学科启示深刻 |
| 4 | 贡献声明清晰合理 |
| 3 | 有贡献声明，但不够明确 |
| 2 | 贡献声明模糊 |
| 1 | 贡献过度声明 |
| 0 | 无贡献声明 |

---

## 领域专属检查

### AI+教育专属检查

```
□ 教育理论依据
  - 是否基于学习科学/教育学理论？
  - 是否说明教学设计原理？

□ 学习效果评估
  - 是否使用教育测量标准？
  - 是否评估学习迁移？

□ 教育伦理
  - 是否考虑教育公平？
  - 是否讨论对学生的影响？

□ 教育场景适配
  - 是否考虑课堂/学校情境？
  - 是否讨论教师角色？

□ 教育政策合规
  - 是否符合教育数据法规？
  - 是否考虑家长/监护人同意？
```

---

### AI+医学专属检查

```
□ 临床验证
  - 是否有临床试验注册？
  - 是否遵循CONSORT/STROBE等指南？

□ 医学伦理
  - 是否获得IRB/伦理委员会批准？
  - 是否符合赫尔辛基宣言？

□ 患者安全
  - 是否讨论误诊/漏诊风险？
  - 是否说明临床决策支持定位？

□ 数据合规
  - 是否符合HIPAA/GDPR医疗数据规定？
  - 是否实施数据脱敏？

□ 临床实用性
  - 是否讨论临床工作流整合？
  - 是否评估医生接受度？
```

---

### AI+社科专属检查

```
□ 社科方法论
  - 是否遵循社科研究规范？
  - 是否处理研究者偏见？

□ 参与者保护
  - 是否保护弱势群体？
  - 是否处理敏感话题？

□ 文化敏感性
  - 是否考虑文化差异？
  - 是否避免文化偏见？

□ 社会伦理
  - 是否讨论社会影响？
  - 是否考虑数字鸿沟？

□ 定性/定量整合
  - 如使用混合方法，整合是否合理？
  - 是否进行三角验证？
```

---

## 工作流集成

```
┌─────────────────────────────────────────────────────────────┐
│                    Pipeline Entry Point                      │
├─────────────────────────────────────────────────────────────┤
│  Input: Repository + Research Domain                         │
│     ↓                                                        │
│  ┌─────────────────────────────────────┐                    │
│  │  Skill 1: AI+Empirical Checker      │                    │
│  │  - AI技术维度 (30分)                 │                    │
│  │  - 实证研究维度 (40分)               │                    │
│  │  - 跨学科整合维度 (30分)             │                    │
│  └─────────────────────────────────────┘                    │
│     ↓                                                        │
│  Score ≥ 75?                                                 │
│     ├── Yes → Proceed to Skill 2                             │
│     │         Score ≥ 85? → 优秀，可直接进入                 │
│     │         Score 75-84? → 合格，可进入                    │
│     └── No  → Trigger Improvement Loop                       │
│                 ↓                                            │
│            Generate Prioritized Tasks                        │
│                 ↓                                            │
│            Re-evaluate after fixes                           │
└─────────────────────────────────────────────────────────────┘
```

---

## 使用示例

### 输入

```json
{
  "repo_url": "https://github.com/example/ai-tutoring-system",
  "readme_content": "...",
  "research_domain": "education",
  "key_files": [
    "main.py",
    "experiments/",
    "data/",
    "configs/",
    "IRB_approval.pdf"
  ]
}
```

### 输出

```markdown
# AI + Empirical Research Repository Standards Report

## 研究信息
- **研究领域**: AI+教育
- **研究类型**: 干预研究（RCT）
- **人类被试**: 是
- **IRB审批**: 已获批

## 总体评分

**Total Score: 82/100**

| 维度 | 得分 | 满分 | 状态 |
|------|------|------|------|
| AI技术维度 | 25 | 30 | ✅ |
| 实证研究维度 | 32 | 40 | ⚠️ |
| 跨学科整合维度 | 25 | 30 | ✅ |

**评级**: 合格 (可进入大纲生成)

## 关键缺失项

| 优先级 | 缺失项 | 影响 | 改进建议 |
|--------|--------|------|----------|
| P1 | 缺少预注册 | 降低研究可信度 | 在OSF进行预注册 |
| P1 | 效应量未报告 | 不符合APA标准 | 添加Cohen's d等效应量 |
| P2 | 学习迁移评估缺失 | 教育价值论证不足 | 添加迁移测试 |
```
